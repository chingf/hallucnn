{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/es3773/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "root = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(root)\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from predify.utils.training import train_pcoders, eval_pcoders\n",
    "\n",
    "from networks_2022 import BranchedNetwork\n",
    "from data.CleanSoundsDataset import CleanSoundsDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which network you're running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pbranchednetwork_all import PBranchedNetwork_AllSeparateHP\n",
    "PNetClass = PBranchedNetwork_AllSeparateHP\n",
    "pnet_name = 'all'\n",
    "p_layers = 'All Layers'\n",
    "chckpt = 25\n",
    "args.append((PNetClass, pnet_name, p_layers, chckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pbranchednetwork_a1 import PBranchedNetwork_A1SeparateHP\n",
    "PNetClass = PBranchedNetwork_A1SeparateHP\n",
    "pnet_name = 'a1'\n",
    "p_layers = 'Layers 1-3'\n",
    "chckpt = 50\n",
    "args.append((PNetClass, pnet_name, p_layers, chckpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engram_dir = '/mnt/smb/locker/issa-locker/users/Erica/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = f'{engram_dir}hcnn/figures/'\n",
    "pickle_dir = f'{engram_dir}hcnn/pickles/'\n",
    "activations_dir = f'{engram_dir}hcnn/activations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "checkpoints_dir = f'{engram_dir}hcnn/checkpoints/'\n",
    "tensorboard_dir = f'{engram_dir}hcnn/tensorboard/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pnet(PNetClass, pnet_name, chckpt):\n",
    "    net = BranchedNetwork(track_encoder_representations=True)\n",
    "    net.load_state_dict(torch.load(f'{engram_dir}networks_2022_weights.pt'))\n",
    "    pnet = PNetClass(net, build_graph=False)\n",
    "    pnet.load_state_dict(torch.load(\n",
    "        f\"{checkpoints_dir}{pnet_name}/{pnet_name}-{chckpt}-regular.pth\",\n",
    "        map_location='cpu'\n",
    "        ))\n",
    "    pnet.to(DEVICE)\n",
    "    pnet.eval();\n",
    "    print(f'Loaded Pnet: {pnet_name}')\n",
    "    print_hps(pnet)\n",
    "    return pnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hps(pnet):\n",
    "    for pc in range(pnet.number_of_pcoders):\n",
    "        print (f\"PCoder{pc+1} : ffm: {getattr(pnet,f'ffm{pc+1}'):0.3f} \\t fbm: {getattr(pnet,f'fbm{pc+1}'):0.3f} \\t erm: {getattr(pnet,f'erm{pc+1}'):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PsychoPhysics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = h5py.File(f\"{engram_dir}PsychophysicsWord2017W_not_resampled.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_metadata = np.load(f\"{engram_dir}PsychophysicsWord2017W_999c6fc475be1e82e114ab9865aa5459e4fd329d.__META.npy\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_key = np.load(f\"{engram_dir}PsychophysicsWord2017W_999c6fc475be1e82e114ab9865aa5459e4fd329d.__META_key.npy\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{engram_dir}PsychophysicsWord2017W_net_performance.p\", 'rb') as f:\n",
    "    net_mistakes = pickle.load(f)['net_mistakes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPsychophysics2017WCleanCochleagrams():\n",
    "    \n",
    "    cochleagrams_clean = []\n",
    "   \n",
    "    cochleagrams = []\n",
    "    for batch_ii in range(0,15300,100):\n",
    "        hdf5_path = '/mnt/smb/locker/issa-locker/users/Erica/cgrams_for_noise_robustness_analysis/PsychophysicsWord2017W_clean/batch_'+str(batch_ii)+'_to_'+str(batch_ii+100)+'.hdf5'\n",
    "        with h5py.File(hdf5_path, 'r') as f_in:\n",
    "            cochleagrams += list(f_in['data'])\n",
    "\n",
    "    return cochleagrams\n",
    "clean_in = getPsychophysics2017WCleanCochleagrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for word in f_metadata['word']:\n",
    "    idx = np.argwhere(f_key == word)\n",
    "    if len(idx) == 0:\n",
    "        labels.append(-1)\n",
    "    else:\n",
    "        labels.append(idx.item())\n",
    "labels = np.array(labels)\n",
    "labels += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = []\n",
    "for _bg in f_metadata['bg']:\n",
    "    bg.append(str(_bg, 'utf-8'))\n",
    "bg = np.array(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = []\n",
    "for _snr in f_metadata['snr']:\n",
    "    _snr = str(_snr, 'utf-8')\n",
    "    if 'inf' in _snr:\n",
    "        _snr = np.inf\n",
    "    elif 'neg' in _snr:\n",
    "        if '3' in _snr:\n",
    "            _snr = -3\n",
    "        elif '6' in _snr:\n",
    "            _snr = -6\n",
    "        elif '9' in _snr:\n",
    "            _snr = -9\n",
    "        else:\n",
    "            raise ValueError('Not found')\n",
    "    else:\n",
    "        if '0' in _snr:\n",
    "            _snr = 0\n",
    "        elif '3' in _snr:\n",
    "            _snr = 3\n",
    "        else:\n",
    "            raise ValueError('Not found')\n",
    "    snr.append(_snr)\n",
    "snr = np.array(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dset = []\n",
    "for _orig_dset in f_metadata['orig_dset']:\n",
    "    _orig_dset = str(_orig_dset, 'utf-8')\n",
    "    _orig_dset = 'WSJ' if 'WSJ' in _orig_dset else 'Timit'\n",
    "    orig_dset.append(_orig_dset)\n",
    "orig_dset = np.array(orig_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save network activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is bad practice! But the warnings are real annoying\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_timit = True\n",
    "bg_types = ['AudScene'] #, 'Babble8Spkr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_activations(\n",
    "    pnet, exclude_timit, bg_types, idx_range\n",
    "    ):\n",
    "    \n",
    "    timesteps = []\n",
    "    distances = []\n",
    "    snrs = []\n",
    "    splits = []\n",
    "    encodetypes = []\n",
    "    pred_accs = []\n",
    "    all_results = {}\n",
    "    n_timesteps = 5\n",
    "    \n",
    "    for idx in idx_range:\n",
    "        idx_results = {}\n",
    "        \n",
    "        # Exclusion criteria\n",
    "        if exclude_timit and orig_dset[idx] != 'WSJ':\n",
    "            continue\n",
    "        if bg[idx] not in bg_types:\n",
    "            continue\n",
    "        if snr[idx] not in [-3]:\n",
    "            continue\n",
    "        \n",
    "        # Clean input\n",
    "        clean_input = clean_in[idx]\n",
    "        clean_input = torch.tensor(\n",
    "            clean_input.reshape((1, 1, 164, 400))).clone()\n",
    "        clean_input = clean_input.to(DEVICE)\n",
    "        \n",
    "        # Activations with clean input\n",
    "        pnet.reset()\n",
    "        logits, _ = pnet(clean_input)\n",
    "        clean_output = logits.max(-1)[1].item()\n",
    "        clean_acc = clean_output == labels[idx]\n",
    "        clean_repr_dict = pnet.backbone.encoder_repr\n",
    "#         for key in ['conv1', 'conv2', 'conv3', 'conv4_W']:\n",
    "#             del clean_repr_dict[key]\n",
    "        idx_results['clean_output'] = clean_output\n",
    "        idx_results['clean_repr_dict'] = clean_repr_dict\n",
    "            \n",
    "        # Noisy input\n",
    "        noisy_input = torch.tensor(\n",
    "            f_in['data'][idx].reshape((1, 1, 164, 400)))\n",
    "        timestep_results = {}\n",
    "        idx_results['timestep_results'] = timestep_results\n",
    "        \n",
    "        # Activations with noisy input\n",
    "        pnet.reset()\n",
    "        for j in range(n_timesteps):\n",
    "            _input = noisy_input if j == 0 else None\n",
    "            if _input is not None:\n",
    "                _input = _input.to(DEVICE)\n",
    "            logits, _ = pnet(_input)\n",
    "            noisy_output = logits.max(-1)[1].item()\n",
    "            noisy_acc = noisy_output == labels[idx]\n",
    "            noisy_repr_dict = pnet.backbone.encoder_repr\n",
    "#             for key in ['conv1', 'conv2', 'conv3', 'conv4_W']:\n",
    "#                 del noisy_repr_dict[key]\n",
    "            timestep_results[j] = {}\n",
    "            timestep_results[j]['noisy_output'] = noisy_output\n",
    "            timestep_results[j]['noisy_repr_dict'] = noisy_repr_dict\n",
    "            \n",
    "        all_results[idx] = idx_results\n",
    "                        \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Pnet: all\n",
      "PCoder1 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "PCoder2 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "PCoder3 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "PCoder4 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "PCoder5 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "Loaded Pnet: a1\n",
      "PCoder1 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "PCoder2 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "PCoder3 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n",
      "Loaded Pnet: conv1\n",
      "PCoder1 : ffm: 0.300 \t fbm: 0.300 \t erm: 0.010\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3a4d4478260e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             )\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{activations_dir}{pnet_name}_{idx_range[0]}-{idx_range[-1]}.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "for arg in args:\n",
    "    PNetClass, pnet_name, p_layers, chckpt = arg\n",
    "    pnet = load_pnet(PNetClass, pnet_name, chckpt)\n",
    "    full_idx_range = np.arange(bg.size)\n",
    "    \n",
    "    for idx_range in np.array_split(full_idx_range, 20):\n",
    "        all_results = save_activations(\n",
    "            pnet, exclude_timit, bg_types, idx_range\n",
    "            )\n",
    "        with open(f'{activations_dir}{pnet_name}_{idx_range[0]}-{idx_range[-1]}.p', 'wb') as f:\n",
    "            pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
