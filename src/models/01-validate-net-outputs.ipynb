{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e9b045",
   "metadata": {},
   "source": [
    "# Tested for `networks_2022`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7dc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pickle\n",
    "root = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(root)\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from predify.utils.training import train_pcoders, eval_pcoders\n",
    "\n",
    "from networks_2022 import BranchedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a54801",
   "metadata": {},
   "outputs": [],
   "source": [
    "engram_dir = '/mnt/smb/locker/issa-locker/users/Erica/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e3148",
   "metadata": {},
   "source": [
    "# Compare Torch net to Tensorflow net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7760982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/issa/users/es3773/hallucnn/src/models/layers.py:78: UserWarning: Inconsistent tf pad calculation in ConvLayer.\n",
      "  warnings.warn('Inconsistent tf pad calculation in ConvLayer.')\n",
      "/share/issa/users/es3773/hallucnn/src/models/layers.py:173: UserWarning: Inconsistent tf pad calculation: 0, 1\n",
      "  warnings.warn(f'Inconsistent tf pad calculation: {pad_left}, {pad_right}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229, 312, 525, 3, 393, 5, 6, 7, 8, 9, 10, 11, 12, 13, 126, 108, 15, 298, 17, 46]\n"
     ]
    }
   ],
   "source": [
    "# Torch network outputs\n",
    "net = BranchedNetwork()\n",
    "net.load_state_dict(torch.load(f'{engram_dir}networks_2022_weights.pt'))\n",
    "\n",
    "y_hats = []\n",
    "\n",
    "with h5py.File(f\"{engram_dir}PsychophysicsWord2017W_not_resampled.hdf5\", 'r') as f_in:\n",
    "    for ind in range(len(f_in['data'])):\n",
    "        word, genre = net(torch.tensor(np.reshape( f_in['data'][ind],(164,400))))\n",
    "        \n",
    "        y_hat = int(torch.argmax(word))\n",
    "        y_hats.append(y_hat)\n",
    "        if len(y_hats) > 20:\n",
    "            break\n",
    "\n",
    "print(y_hats[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5448e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229 312 525   3 393   5   6   7   8   9  10  11  12  13 126 108  15 298\n",
      "  17  46]\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow network outputs\n",
    "tf_y_hats = np.array([229, 312, 525, 3, 393, 5, 6, 7, 8, 9, 10, 11, 12, 13, 126, 108, 15, 298, 17, 46, 152, 388, 278, 459, 256, 23, 14, 25, 26, 27, 129, 29, 30, 31, 63, 337, 34, 216, 36, 37, 38, 241, 40, 41, 183, 42, 393, 240, 45, 196, 46, 487, 48, 129, 142, 51, 269, 519, 54, 55, 284, 57, 65, 58, 239, 59, 376, 62, 63, 158, 345, 66, 67, 68, 69, 70, 394, 72, 494, 74, 109, 75, 48, 78, 343, 455, 487, 413, 82, 109, 84, 496, 243, 490, 9, 24, 89, 0, 110, 259])\n",
    "tf_y_hats_no_Dropout = [229, 312, 525, 3, 393, 5, 6, 7, 8, 9, 10, 11, 12, 13, 126, 108, 15, 298, 17, 46, 152, 388, 278, 459, 256, 23, 14, 25, 26, 27, 129, 29, 30, 31, 63, 337, 34, 216, 36, 37, 38, 241, 40, 41, 183, 42, 393, 240, 45, 196, 46, 487, 48, 129, 142, 51, 269, 519, 54, 55, 284, 57, 65, 58, 239, 59, 376, 62, 63, 158, 345, 66, 67, 68, 69, 70, 394, 72, 494, 74, 109, 75, 48, 78, 343, 455, 487, 413, 82, 109, 84, 496, 243, 490, 9, 24, 89, 0, 110, 259]\n",
    "print(tf_y_hats[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e4f83d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/es3773/.conda/envs/hcnn/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Number of matches\n",
    "print(len(np.where(tf_y_hats == np.array(y_hats))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88827f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6390eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fef221ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for ii in range(len(tf_y_hats)):\n",
    "    if tf_y_hats[ii] == labels[ii]:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f57bda44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9b24e",
   "metadata": {},
   "source": [
    "# Compare Torch net to Ground truth labels\n",
    "Also save the info on which examples the net gets correct/incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aee1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_metadata = np.load(f\"{engram_dir}PsychophysicsWord2017W_999c6fc475be1e82e114ab9865aa5459e4fd329d.__META.npy\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292b2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_key = np.load(f\"{engram_dir}PsychophysicsWord2017W_999c6fc475be1e82e114ab9865aa5459e4fd329d.__META_key.npy\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8600f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for word in f_metadata['word']:\n",
    "    idx = np.argwhere(f_key == word)\n",
    "    if len(idx) == 0:\n",
    "        labels.append(-1)\n",
    "    else:\n",
    "        labels.append(idx.item())\n",
    "labels = np.array(labels)\n",
    "labels += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215029b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = []\n",
    "corrects = []\n",
    "\n",
    "with h5py.File(f\"{engram_dir}PsychophysicsWord2017W_not_resampled.hdf5\", 'r') as f_in:\n",
    "    for ind in range(len(f_in['data'])):\n",
    "        word, genre =net(torch.tensor(np.reshape( f_in['data'][ind],(164,400))))\n",
    "        \n",
    "        y_hat = int(torch.argmax(word))\n",
    "        y_hats.append(y_hat)\n",
    "        corrects.append(y_hat == labels[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec79283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save net predictions and mistakes to file\n",
    "with open(f\"{engram_dir}PsychophysicsWord2017W_net_performance.p\", 'wb') as f:\n",
    "    results = {\n",
    "        'net_pred': np.array(y_hats),\n",
    "        'net_mistakes': np.logical_not(corrects)\n",
    "    }\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361f636",
   "metadata": {},
   "source": [
    "# Compare Predified-Net with Torch Net\n",
    "The outputs should match at timestep 0 of the predified-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "checkpoints_dir = f'{engram_dir}hcnn/checkpoints/'\n",
    "tensorboard_dir = f'{engram_dir}hcnn/tensorboard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc48b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which predified network you want to test\n",
    "from pbranchednetwork_all import PBranchedNetwork_AllSeparateHP\n",
    "PNetClass = PBranchedNetwork_AllSeparateHP\n",
    "pnet_name = 'all'\n",
    "p_layers = 'All Layers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8745a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch network outputs from before\n",
    "print(y_hats[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90404daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predified network outputs\n",
    "pnet = PNetClass(net, build_graph=True)\n",
    "pnet.load_state_dict(torch.load(\n",
    "    f\"{checkpoints_dir}{pnet_name}/{pnet_name}-50-regular.pth\",\n",
    "    map_location='cpu'\n",
    "    ))\n",
    "pnet.to(DEVICE)\n",
    "pnet.build_graph = False        # only required for training\n",
    "pnet.eval()\n",
    "\n",
    "y_hats = []\n",
    "\n",
    "f_in = h5py.File(f\"{engram_dir}PsychophysicsWord2017W_not_resampled.hdf5\", 'r')\n",
    "for ind in range(len(f_in['data'])):\n",
    "    pnet.reset()\n",
    "    _input = torch.tensor(np.reshape(f_in['data'][ind],(164,400))).to(DEVICE)\n",
    "    word, genre = pnet(_input)\n",
    "    y_hat = int(torch.argmax(word))\n",
    "    y_hats.append(y_hat)\n",
    "    if len(y_hats) > 20:\n",
    "        break\n",
    "        \n",
    "print(y_hats[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfc00b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
