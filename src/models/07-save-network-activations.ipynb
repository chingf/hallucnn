{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96d4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from scipy.stats import pearsonr\n",
    "root = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(root)\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from predify.utils.training import train_pcoders, eval_pcoders\n",
    "\n",
    "from networks_2022 import BranchedNetwork\n",
    "from data.CleanSoundsDataset import CleanSoundsDataset\n",
    "from data.NoisyDataset import NoisyDataset, FullNoisyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe5e29",
   "metadata": {},
   "source": [
    "# PNet parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a3c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pbranchednetwork_all import PBranchedNetwork_AllSeparateHP\n",
    "PNetClass = PBranchedNetwork_AllSeparateHP\n",
    "pnet_name = 'pnet'\n",
    "chckpt = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0593f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 5\n",
    "layers = ['conv1', 'conv2', 'conv3', 'conv4_W', 'fc6_W']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f32ec5",
   "metadata": {},
   "source": [
    "# Paths to relevant directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7152498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engram_dir = '/mnt/smb/locker/abbott-locker/hcnn/'\n",
    "activations_dir = f'{engram_dir}activations_pnet/'\n",
    "checkpoints_dir = f'{engram_dir}checkpoints/'\n",
    "tensorboard_dir = f'{engram_dir}tensorboard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f2cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3174fa",
   "metadata": {},
   "source": [
    "# Helper functions to load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7296d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams(tf_dir, bg, snr, shared=False):\n",
    "    if shared:\n",
    "        raise ValueError('Not implemented for shared hyperparameters.')\n",
    "        \n",
    "    hyperparams = []\n",
    "    tf_file_dir = f'{tf_dir}hyper_{bg}_snr{snr}/'\n",
    "    for tf_file in os.listdir(tf_file_dir):\n",
    "        tf_file = f'{tf_file_dir}{tf_file}'\n",
    "        ea = event_accumulator.EventAccumulator(tf_file)\n",
    "        ea.Reload()\n",
    "        for i in range(1, 6):\n",
    "            hps = {}\n",
    "            ffm = ea.Scalars(f'Hyperparam/pcoder{i}_feedforward')[-1].value\n",
    "            fbm = ea.Scalars(f'Hyperparam/pcoder{i}_feedback')[-1].value\n",
    "            erm = ea.Scalars(f'Hyperparam/pcoder{i}_error')[-1].value\n",
    "            hps['ffm'] = ffm\n",
    "            hps['fbm'] = fbm\n",
    "            hps['erm'] = erm\n",
    "            hyperparams.append(hps)\n",
    "        break\n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487e4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pnet(PNetClass, pnet_name, chckpt, hyperparams=None):\n",
    "    net = BranchedNetwork(track_encoder_representations=True)\n",
    "    net.load_state_dict(torch.load(f'{engram_dir}networks_2022_weights.pt'))\n",
    "    pnet = PNetClass(net, build_graph=False)\n",
    "    pnet.load_state_dict(torch.load(\n",
    "        f\"{checkpoints_dir}{pnet_name}/{pnet_name}-{chckpt}-regular.pth\",\n",
    "        map_location='cpu'\n",
    "        ))\n",
    "    if hyperparams is not None:\n",
    "        pnet.set_hyperparameters(hyperparams)\n",
    "    pnet.to(DEVICE)\n",
    "    pnet.eval();\n",
    "    print(f'Loaded Pnet: {pnet_name}')\n",
    "    print_hps(pnet)\n",
    "    return pnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda98679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hps(pnet):\n",
    "    for pc in range(pnet.number_of_pcoders):\n",
    "        print (f\"PCoder{pc+1} : ffm: {getattr(pnet,f'ffm{pc+1}'):0.3f} \\t fbm: {getattr(pnet,f'fbm{pc+1}'):0.3f} \\t erm: {getattr(pnet,f'erm{pc+1}'):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1718c",
   "metadata": {},
   "source": [
    "# Helper functions to save activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c486a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units_per_layer = {\n",
    "    'conv1': (96, 55, 134), 'conv2': (256, 14, 34),\n",
    "    'conv3': (512, 7, 17), 'conv4_W': (1024, 7, 17),\n",
    "    'conv5_W': (512, 7, 17), 'fc6_W': (4096,)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58884191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pnet(pnet, _input):\n",
    "    pnet.reset()\n",
    "    reconstructions = []\n",
    "    activations = []\n",
    "    logits = []\n",
    "    output = []\n",
    "    for t in range(n_timesteps):\n",
    "        _input_t = _input if t == 0 else None\n",
    "        logits_t, _ = pnet(_input_t)\n",
    "        x = pnet.pcoder1.prd\n",
    "        reconstructions.append(pnet.pcoder1.prd[0,0].cpu().numpy())\n",
    "        activations.append(pnet.backbone.encoder_repr)\n",
    "        logits.append(logits_t.cpu().numpy().squeeze())\n",
    "        output.append(logits_t.max(-1)[1].item())\n",
    "    return reconstructions, activations, logits, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b123dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_activations(pnet, dset, hdf5_path):\n",
    "    \n",
    "    with h5py.File(hdf5_path, 'x') as f_out:\n",
    "        data_dict = {}\n",
    "        data_dict['label'] = f_out.create_dataset(\n",
    "            'label', dset.n_data, dtype='float32'\n",
    "            )\n",
    "        data_dict['clean_correct'] = f_out.create_dataset(\n",
    "            'clean_correct', dset.n_data, dtype='float32'\n",
    "            )\n",
    "        for layer_idx, layer in enumerate(layers):\n",
    "            reconstr_dim = (dset.n_data, 164, 400)\n",
    "            activ_dim = (dset.n_data,) + n_units_per_layer[layer]\n",
    "            logit_dim = (dset.n_data, 531)\n",
    "            for timestep in range(n_timesteps):\n",
    "                data_dict[f'{layer}_{timestep}_activations'] = f_out.create_dataset(\n",
    "                    f'{layer}_{timestep}_activations', activ_dim, dtype='float32'\n",
    "                    )\n",
    "                data_dict[f'{layer}_{timestep}_clean_activations'] = f_out.create_dataset(\n",
    "                    f'{layer}_{timestep}_clean_activations', activ_dim, dtype='float32'\n",
    "                    )\n",
    "                if layer_idx == 0:\n",
    "                    data_dict[f'{timestep}_reconstructions'] = f_out.create_dataset(\n",
    "                        f'{timestep}_reconstructions', reconstr_dim, dtype='float32'\n",
    "                        )\n",
    "                    data_dict[f'{timestep}_logits'] = f_out.create_dataset(\n",
    "                        f'{timestep}_logits', logit_dim, dtype='float32'\n",
    "                        )\n",
    "                    data_dict[f'{timestep}_output'] = f_out.create_dataset(\n",
    "                        f'{timestep}_output', dset.n_data, dtype='float32'\n",
    "                        )\n",
    "                    data_dict[f'{timestep}_clean_logits'] = f_out.create_dataset(\n",
    "                        f'{timestep}_clean_logits', logit_dim, dtype='float32'\n",
    "                        )\n",
    "                    data_dict[f'{timestep}_clean_output'] = f_out.create_dataset(\n",
    "                        f'{timestep}_clean_output', dset.n_data, dtype='float32'\n",
    "                        )\n",
    "    \n",
    "        for idx in range(dset.n_data):\n",
    "            # Noisy input\n",
    "            noisy_in, label = dset[idx]\n",
    "            data_dict['label'][idx] = label\n",
    "            noisy_in = noisy_in.to(DEVICE)\n",
    "            reconstructions, activations, logits, output = run_pnet(pnet, noisy_in)\n",
    "            for timestep in range(n_timesteps):\n",
    "                for layer in layers:\n",
    "                    data_dict[f'{layer}_{timestep}_activations'][idx] = \\\n",
    "                        activations[timestep][layer]\n",
    "                data_dict[f'{timestep}_reconstructions'][idx] = \\\n",
    "                    reconstructions[timestep]\n",
    "                data_dict[f'{timestep}_logits'][idx] = \\\n",
    "                    logits[timestep]\n",
    "                data_dict[f'{timestep}_output'][idx] = output[timestep]\n",
    "\n",
    "            # Clean input\n",
    "            clean_in = torch.tensor(\n",
    "                dset.clean_in[idx].reshape((1, 1, 164, 400))\n",
    "                ).to(DEVICE)\n",
    "            reconstructions, activations, logits, output = run_pnet(pnet, clean_in)\n",
    "            data_dict['clean_correct'][idx] = label == output\n",
    "            for timestep in range(n_timesteps):\n",
    "                for layer in layers:\n",
    "                    data_dict[f'{layer}_{timestep}_clean_activations'][idx] = \\\n",
    "                        activations[timestep][layer]\n",
    "                data_dict[f'{timestep}_clean_logits'][idx] = \\\n",
    "                    logits[timestep]\n",
    "                data_dict[f'{timestep}_clean_output'][idx] = output[timestep]\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b16d6",
   "metadata": {},
   "source": [
    "# Run activation-saving functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc0a5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = ['AudScene', 'Babble8Spkr']\n",
    "snrs = [-9.0, -6.0, -3.0, 0.0, 3.0]\n",
    "tf_dir = f'{tensorboard_dir}lr_0.01x/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c206980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudScene, SNR = -9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/issa/users/es3773/hallucnn/src/models/layers.py:78: UserWarning: Inconsistent tf pad calculation in ConvLayer.\n",
      "  warnings.warn('Inconsistent tf pad calculation in ConvLayer.')\n",
      "/share/issa/users/es3773/hallucnn/src/models/layers.py:173: UserWarning: Inconsistent tf pad calculation: 0, 1\n",
      "  warnings.warn(f'Inconsistent tf pad calculation: {pad_left}, {pad_right}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.055 \t fbm: 0.816 \t erm: 0.007\n",
      "PCoder2 : ffm: 0.385 \t fbm: 0.244 \t erm: -0.000\n",
      "PCoder3 : ffm: 0.163 \t fbm: 0.554 \t erm: 0.011\n",
      "PCoder4 : ffm: 0.220 \t fbm: 0.420 \t erm: 0.021\n",
      "PCoder5 : ffm: 0.148 \t fbm: 0.000 \t erm: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/es3773/.conda/envs/hcnn/lib/python3.6/site-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/home/es3773/.conda/envs/hcnn/lib/python3.6/site-packages/predify/modules/base.py:260: UserWarning: Using a target size (torch.Size([164, 400])) that is different to the input size (torch.Size([1, 1, 164, 400])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  self.prediction_error  = nn.functional.mse_loss(self.prd, target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Babble8Spkr, SNR = -9.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.485 \t fbm: 0.309 \t erm: 0.017\n",
      "PCoder2 : ffm: 0.074 \t fbm: 0.505 \t erm: -0.006\n",
      "PCoder3 : ffm: 0.626 \t fbm: 0.168 \t erm: -0.009\n",
      "PCoder4 : ffm: 0.485 \t fbm: 0.355 \t erm: 0.015\n",
      "PCoder5 : ffm: 0.246 \t fbm: 0.000 \t erm: 0.015\n",
      "AudScene, SNR = -6.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.145 \t fbm: 0.680 \t erm: 0.010\n",
      "PCoder2 : ffm: 0.565 \t fbm: 0.184 \t erm: 0.006\n",
      "PCoder3 : ffm: 0.178 \t fbm: 0.362 \t erm: 0.002\n",
      "PCoder4 : ffm: 0.150 \t fbm: 0.415 \t erm: 0.023\n",
      "PCoder5 : ffm: 0.116 \t fbm: 0.000 \t erm: 0.012\n",
      "Babble8Spkr, SNR = -6.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.500 \t fbm: 0.159 \t erm: 0.021\n",
      "PCoder2 : ffm: 0.226 \t fbm: 0.473 \t erm: 0.004\n",
      "PCoder3 : ffm: 0.342 \t fbm: 0.450 \t erm: 0.005\n",
      "PCoder4 : ffm: 0.333 \t fbm: 0.377 \t erm: 0.014\n",
      "PCoder5 : ffm: 0.191 \t fbm: 0.000 \t erm: 0.012\n",
      "AudScene, SNR = -3.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.223 \t fbm: 0.555 \t erm: 0.003\n",
      "PCoder2 : ffm: 0.651 \t fbm: 0.179 \t erm: 0.004\n",
      "PCoder3 : ffm: 0.137 \t fbm: 0.355 \t erm: 0.000\n",
      "PCoder4 : ffm: 0.141 \t fbm: 0.386 \t erm: 0.024\n",
      "PCoder5 : ffm: 0.123 \t fbm: 0.000 \t erm: 0.008\n",
      "Babble8Spkr, SNR = -3.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.431 \t fbm: 0.140 \t erm: 0.029\n",
      "PCoder2 : ffm: 0.628 \t fbm: 0.209 \t erm: -0.001\n",
      "PCoder3 : ffm: 0.291 \t fbm: 0.511 \t erm: 0.019\n",
      "PCoder4 : ffm: 0.211 \t fbm: 0.394 \t erm: 0.012\n",
      "PCoder5 : ffm: 0.171 \t fbm: 0.000 \t erm: 0.007\n",
      "AudScene, SNR = 0.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.376 \t fbm: 0.280 \t erm: 0.016\n",
      "PCoder2 : ffm: 0.712 \t fbm: 0.165 \t erm: -0.002\n",
      "PCoder3 : ffm: 0.199 \t fbm: 0.378 \t erm: 0.013\n",
      "PCoder4 : ffm: 0.158 \t fbm: 0.328 \t erm: 0.016\n",
      "PCoder5 : ffm: 0.132 \t fbm: 0.000 \t erm: 0.011\n",
      "Babble8Spkr, SNR = 0.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.449 \t fbm: 0.168 \t erm: 0.031\n",
      "PCoder2 : ffm: 0.854 \t fbm: 0.064 \t erm: -0.003\n",
      "PCoder3 : ffm: 0.435 \t fbm: 0.277 \t erm: 0.020\n",
      "PCoder4 : ffm: 0.159 \t fbm: 0.381 \t erm: 0.020\n",
      "PCoder5 : ffm: 0.181 \t fbm: 0.000 \t erm: 0.002\n",
      "AudScene, SNR = 3.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.273 \t fbm: 0.419 \t erm: 0.008\n",
      "PCoder2 : ffm: 0.628 \t fbm: 0.189 \t erm: 0.004\n",
      "PCoder3 : ffm: 0.233 \t fbm: 0.427 \t erm: 0.015\n",
      "PCoder4 : ffm: 0.224 \t fbm: 0.322 \t erm: 0.016\n",
      "PCoder5 : ffm: 0.149 \t fbm: 0.000 \t erm: 0.009\n",
      "Babble8Spkr, SNR = 3.0\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.447 \t fbm: 0.170 \t erm: 0.030\n",
      "PCoder2 : ffm: 0.845 \t fbm: 0.068 \t erm: -0.004\n",
      "PCoder3 : ffm: 0.507 \t fbm: 0.291 \t erm: 0.027\n",
      "PCoder4 : ffm: 0.206 \t fbm: 0.334 \t erm: 0.022\n",
      "PCoder5 : ffm: 0.226 \t fbm: 0.000 \t erm: 0.002\n"
     ]
    }
   ],
   "source": [
    "for snr in snrs:\n",
    "    for bg in bgs:\n",
    "        print(f'{bg}, SNR = {snr}')\n",
    "        hdf5_path = f'{activations_dir}{bg}_snr{int(snr)}.hdf5'\n",
    "        hyperparams = get_hyperparams(tf_dir, bg, snr)\n",
    "        pnet = load_pnet(PNetClass, pnet_name, chckpt, hyperparams)\n",
    "        dset = NoisyDataset(bg, snr)\n",
    "        save_activations(pnet, dset, hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc5059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
