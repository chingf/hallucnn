{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b3aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import configs\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from predify.utils.training import train_pcoders, eval_pcoders\n",
    "\n",
    "from models.networks_2022 import BranchedNetwork\n",
    "from data.CleanSoundsDataset import CleanSoundsDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440077cd",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359c8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engram_dir = '/mnt/smb/locker/abbott-locker/hcnn/'\n",
    "checkpoints_dir = f'{engram_dir}checkpoints/'\n",
    "tensorboard_dir = f'{engram_dir}tensorboard/'\n",
    "activations_dir = f'{engram_dir}activations_pnet_all/'\n",
    "pickles_dir = f'{engram_dir}pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edcaf786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdd03c",
   "metadata": {},
   "source": [
    "# Distance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f1b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ed7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few distance metrics\n",
    "\n",
    "def row_rms(A, B):\n",
    "    \"\"\"\n",
    "    RMS across rows\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    \n",
    "    if len(A.shape) == 1:\n",
    "        stim = A - B\n",
    "        return np.sqrt(np.mean(stim * stim, axis = 0))\n",
    "    \n",
    "    rmses = []\n",
    "    for idx in range(A.shape[0]):\n",
    "        a = A[idx]\n",
    "        b = B[idx]\n",
    "        a, b = a.T, b.T\n",
    "        stim = (a - b)\n",
    "        out = np.sqrt(np.mean(stim * stim, axis = 0))\n",
    "        rmses.append(out)\n",
    "    return np.mean(rmses)\n",
    "\n",
    "def rms(A, B):\n",
    "    \"\"\"\n",
    "    RMS of flattened vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "        \n",
    "    stim = A - B\n",
    "    out = np.sqrt(np.mean(stim * stim))\n",
    "\n",
    "    return out\n",
    "\n",
    "def tanimoto_distance(A, B):\n",
    "    \"\"\"\n",
    "    Tanimoto distance of flattened vector\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "    \n",
    "    _out = np.dot(A, B)/(np.linalg.norm(A)**2 + np.linalg.norm(B)**2 - np.dot(A,B))\n",
    "    return _out\n",
    "    \n",
    "def cosine_similarity(A, B):\n",
    "    \"\"\"\n",
    "    Cosine similarity of flattened vector\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "    \n",
    "    if len(A.shape) == 1:\n",
    "        return np.dot(A, B)/(np.linalg.norm(A)*np.linalg.norm(B))\n",
    "    \n",
    "    out = []\n",
    "    for channel in range(n_channels):\n",
    "        a = A[channel]\n",
    "        b = B[channel]\n",
    "        _out = np.dot(a, b)/(np.linalg.norm(a)+np.linalg.norm(b)-np.dot(a,b))\n",
    "        if np.isnan(_out):\n",
    "            print(f'nan: {np.linalg.norm(a)}, {np.linalg.norm(b)}')\n",
    "        out.append(_out)\n",
    "\n",
    "    return np.mean(out)\n",
    "\n",
    "def pearsonr_sim(A, B):\n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "    pear, _ = pearsonr(A, B)\n",
    "    return pear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3f4db",
   "metadata": {},
   "source": [
    "# Function to collect correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0cc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_correlations(results, dist_func, undead_units):\n",
    "    labels = np.array(results['label'])\n",
    "    idxs = np.arange(labels.size)\n",
    "    \n",
    "    popln_shuffle = []\n",
    "    popln_shuffle_undead = []\n",
    "    popln_timestep = []\n",
    "    popln_layer = []\n",
    "    \n",
    "    unit_shuffle = []\n",
    "    unit_shuffle_alive = []\n",
    "    unit_timestep = []\n",
    "    unit_layer = []\n",
    "    layers = ['conv1', 'conv2', 'conv3', 'conv4_W', 'conv5_W', 'fc6_W']\n",
    "    \n",
    "    n_timesteps = 5\n",
    "    for t in range(n_timesteps):\n",
    "        for l in layers:\n",
    "            unit_noisy_response = []\n",
    "            unit_clean_response = []\n",
    "            undead_units_l = undead_units[l]\n",
    "            for i in idxs:\n",
    "                noisy_activ = results[f'{l}_{t}_activations'][i]\n",
    "                clean_activ = results[f'{l}_{t}_clean_activations'][i]\n",
    "                noisy_activ = noisy_activ.flatten()\n",
    "                clean_activ = clean_activ.flatten()\n",
    "                unit_noisy_response.append(noisy_activ)\n",
    "                unit_clean_response.append(clean_activ)\n",
    "\n",
    "                # Popln Corr\n",
    "                dist = dist_func(noisy_activ, clean_activ)\n",
    "                dist_undead = dist_func(\n",
    "                    noisy_activ[undead_units_l],\n",
    "                    clean_activ[undead_units_l]\n",
    "                    )\n",
    "                popln_shuffle.append(dist)\n",
    "                popln_shuffle_undead.append(dist_undead)\n",
    "                popln_timestep.append(t)\n",
    "                popln_layer.append(l)\n",
    "\n",
    "            # Popln Corr\n",
    "            unit_noisy_response = np.array(unit_noisy_response)\n",
    "            unit_clean_response = np.array(unit_clean_response)\n",
    "            for unit in np.arange(unit_noisy_response.shape[1]):               \n",
    "                dist = dist_func(\n",
    "                    unit_noisy_response[:,unit],\n",
    "                    unit_clean_response[:,unit]\n",
    "                    )\n",
    "                unit_shuffle.append(dist)\n",
    "                unit_shuffle_alive.append(undead_units_l[unit])\n",
    "                unit_timestep.append(t)\n",
    "                unit_layer.append(l)\n",
    "        \n",
    "    results = {\n",
    "        'popln_shuffle': popln_shuffle,\n",
    "        'popln_shuffle_undead': popln_shuffle_undead,\n",
    "        'popln_timestep': popln_timestep,\n",
    "        'popln_layer': popln_layer,\n",
    "        'unit_shuffle': unit_shuffle,\n",
    "        'unit_shuffle_alive': unit_shuffle_alive,\n",
    "        'unit_timestep': unit_timestep,\n",
    "        'unit_layer': unit_layer\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ad3af2",
   "metadata": {},
   "source": [
    "# Run and save correlations to pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d634a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is bad practice! But the warnings are real annoying\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8f0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = 'repr_pearsonr'\n",
    "shuff_file_prefix = 'shuffle_pearsonr'\n",
    "dist_func = pearsonr_sim\n",
    "bgs = ['AudScene']\n",
    "snrs = [-9., -6.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c9e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pickles_dir}dead_units.p', 'rb') as f:\n",
    "    undead_units = pickle.load(f)['undead_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b98a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudScene, SNR -9.0\n",
      "Running correlations\n"
     ]
    }
   ],
   "source": [
    "for bg in bgs:\n",
    "    for snr in snrs:                                                            \n",
    "        print(f'{bg}, SNR {snr}')                                               \n",
    "        results_path = f'{activations_dir}{bg}_snr{int(snr)}.hdf5'              \n",
    "        results = h5py.File(results_path, 'r')                                \n",
    "        print('Running correlations')                                           \n",
    "        results = eval_correlations(                      \n",
    "            results, dist_func, undead_units                               \n",
    "            )                                                                   \n",
    "        with open(f'{pickles_dir}{file_prefix}_{bg}_snr{snr}.p', 'wb') as f:    \n",
    "            pickle.dump(results, f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
