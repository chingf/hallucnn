{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gamma\n",
    "from models.networks_2022 import BranchedNetwork\n",
    "from models.priming_pbranchednetwork_all import PBranchedNetwork_AllSeparateHP\n",
    "from data.ValidationDataset import NoisyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from tensorboard.backend.event_processing import event_accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which network to test\n",
    "pnet_name = 'pnet'\n",
    "chckpt = 1960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engram_dir = '/Users/chingfang/temp_locker/'\n",
    "engram_dir = '/mnt/smb/locker/abbott-locker/hcnn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set up parameters\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')\n",
    "checkpoints_dir = f'{engram_dir}1_checkpoints/'\n",
    "tensorboard_dir = f'{engram_dir}1_tensorboard/'\n",
    "activations_dir = f'{engram_dir}3_validation_activations/{pnet_name}/'\n",
    "hyp_dir = f'{engram_dir}2_hyperp/{pnet_name}/'\n",
    "PNetClass = PBranchedNetwork_AllSeparateHP\n",
    "n_timesteps = 5\n",
    "layers = ['conv1', 'conv2', 'conv3', 'conv4_W', 'conv5_W', 'fc6_W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = 'pinkNoise'\n",
    "snr = -9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/hallucnn/src/models/layers.py:78: UserWarning: Inconsistent tf pad calculation in ConvLayer.\n",
      "  warnings.warn('Inconsistent tf pad calculation in ConvLayer.')\n",
      "/share/ctn/users/cf2794/Code/hallucnn/src/models/layers.py:173: UserWarning: Inconsistent tf pad calculation: 0, 1\n",
      "  warnings.warn(f'Inconsistent tf pad calculation: {pad_left}, {pad_right}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = BranchedNetwork()\n",
    "pnet = PNetClass(net, build_graph=True)\n",
    "def print_hps(pnet):\n",
    "    for pc in range(pnet.number_of_pcoders):\n",
    "        string = f\"PCoder{pc+1} : ffm: {getattr(pnet,f'ffm{pc+1}'):0.3f} \\t\"\n",
    "        string += f\"fbm: {getattr(pnet,f'fbm{pc+1}'):0.3f} \\t\"\n",
    "        string += f\"erm: {getattr(pnet,f'erm{pc+1}'):0.3f}\"\n",
    "        print(string)\n",
    "pnet.load_state_dict(torch.load(\n",
    "    f\"{checkpoints_dir}{pnet_name}/{pnet_name}-{chckpt}-regular.pth\",\n",
    "    map_location='cpu'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams(tf_filepath, bg, snr):\n",
    "    hyperparams = []\n",
    "    ea = event_accumulator.EventAccumulator(tf_filepath)\n",
    "    ea.Reload()\n",
    "    eval_score = [0]\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        try:\n",
    "            score_over_t = 0.\n",
    "            for t in np.arange(1,5):\n",
    "                score_over_t += ea.Scalars(f'NoisyPerf/Epoch#{epoch}')[t].value\n",
    "                epoch += 1\n",
    "            score_over_t /= 4\n",
    "            eval_score.append(score_over_t)\n",
    "        except Exception as e:\n",
    "            break\n",
    "    for i in range(1, 6):\n",
    "        hps = {}\n",
    "        ffm = ea.Scalars(f'Hyperparam/pcoder{i}_feedforward')[-1].value\n",
    "        fbm = ea.Scalars(f'Hyperparam/pcoder{i}_feedback')[-1].value\n",
    "        erm = ea.Scalars(f'Hyperparam/pcoder{i}_error')[-1].value\n",
    "        if np.isnan(ffm) or np.isnan(fbm) or np.isnan(erm):\n",
    "            return None, 0.\n",
    "        hps['ffm'] = ffm\n",
    "        hps['fbm'] = fbm\n",
    "        hps['erm'] = erm\n",
    "        hyperparams.append(hps)\n",
    "    return hyperparams, eval_score[-1]\n",
    "\n",
    "def load_pnet(PNetClass, pnet_name, chckpt, hyperparams=None):\n",
    "    net = BranchedNetwork(track_encoder_representations=True)\n",
    "    net.load_state_dict(torch.load(f'{engram_dir}networks_2022_weights.pt'))\n",
    "    pnet = PNetClass(net, build_graph=False)\n",
    "    pnet.load_state_dict(torch.load(\n",
    "        f\"{checkpoints_dir}{pnet_name}/{pnet_name}-{chckpt}-regular.pth\",\n",
    "        map_location='cpu'\n",
    "        ))\n",
    "    if hyperparams is not None:\n",
    "        pnet.set_hyperparameters(hyperparams)\n",
    "    pnet.to(DEVICE)\n",
    "    pnet.eval();\n",
    "    print(f'Loaded Pnet: {pnet_name}')\n",
    "    print_hps(pnet)\n",
    "    return pnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pinkNoise, SNR -9.0 uses 34545.1 with valid score 0.37640000134706497\n",
      "Loaded Pnet: pnet\n",
      "PCoder1 : ffm: 0.749 \tfbm: 0.248 \term: 0.026\n",
      "PCoder2 : ffm: 0.969 \tfbm: 0.031 \term: -0.002\n",
      "PCoder3 : ffm: 0.743 \tfbm: 0.256 \term: 0.016\n",
      "PCoder4 : ffm: 0.133 \tfbm: 0.850 \term: 0.026\n",
      "PCoder5 : ffm: 0.301 \tfbm: 0.000 \term: -0.041\n"
     ]
    }
   ],
   "source": [
    "tf_dir = f'{hyp_dir}hyper_{bg}_snr{snr}/'\n",
    "best_score = 0.\n",
    "best_hyperparams = None\n",
    "best_tf_file = None\n",
    "for tf_file in os.listdir(tf_dir):\n",
    "    if not tf_file.startswith('event'): continue\n",
    "    tf_filepath = f'{tf_dir}{tf_file}'\n",
    "    tf_file = tf_file.split('edu.')[-1]\n",
    "    hyperparams, score = get_hyperparams(tf_filepath, bg, snr)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_hyperparams = hyperparams\n",
    "        best_tf_file = tf_file\n",
    "print(f'{bg}, SNR {snr} uses {best_tf_file} with valid score {best_score}')\n",
    "\n",
    "# Use the best hyperparameter set\n",
    "pnet = load_pnet(PNetClass, pnet_name, chckpt, best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCoder1 : ffm: 0.300 \tfbm: 0.300 \term: 0.010\n",
      "PCoder2 : ffm: 0.300 \tfbm: 0.300 \term: 0.010\n",
      "PCoder3 : ffm: 0.300 \tfbm: 0.300 \term: 0.010\n",
      "PCoder4 : ffm: 0.300 \tfbm: 0.300 \term: 0.010\n",
      "PCoder5 : ffm: 0.300 \tfbm: 0.300 \term: 0.010\n"
     ]
    }
   ],
   "source": [
    "# pnet.to(DEVICE)\n",
    "# pnet.build_graph = False\n",
    "# pnet.eval();\n",
    "# print_hps(pnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = NoisyDataset(bg=bg, snr=snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify data indices for correct/incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_correct = []\n",
    "pred_correct = []\n",
    "ff_output = []\n",
    "pred_output = []\n",
    "\n",
    "for i in range(200):\n",
    "    cgram, label = dset[i]\n",
    "    label = label.item()\n",
    "    pnet.reset()\n",
    "    for t in range(n_timesteps):\n",
    "        _input = cgram if t == 0 else None # Clean cochleagram\n",
    "        if _input is not None:\n",
    "            _input = _input.unsqueeze(0)\n",
    "            _input = _input.to(DEVICE)\n",
    "        output_logits, _ = pnet(_input)\n",
    "        output = np.argmax(output_logits.cpu().numpy())\n",
    "        if t == 0:\n",
    "            ff_correct.append(output == label)\n",
    "            ff_output.append(output)\n",
    "        if t == 4:\n",
    "            pred_correct.append(output == label)\n",
    "            pred_output.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.145"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ff_correct)/len(ff_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.175"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_correct)/len(pred_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt priming experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "primed_ff_correct = []\n",
    "primed_ff_output = []\n",
    "\n",
    "for i in range(200):\n",
    "    priming_cgram, _ = dset[np.random.choice(len(dset))]\n",
    "    \n",
    "    # Prime with cgram\n",
    "    pnet.reset()\n",
    "    for t in range(n_timesteps):\n",
    "        _input = priming_cgram if t == 0 else None\n",
    "        if _input is not None:\n",
    "            _input = _input.unsqueeze(0).to(DEVICE)\n",
    "        _, _ = pnet(_input)\n",
    "    \n",
    "    # Now run a regular forward pass\n",
    "    cgram, label = dset[i]\n",
    "    label = label.item()\n",
    "    _input = cgram.unsqueeze(0).to(DEVICE)\n",
    "    output_logits, _ = pnet(_input, force_no_reset=True)\n",
    "    output = np.argmax(output_logits.cpu().numpy())\n",
    "    primed_ff_correct.append(output == label)\n",
    "    primed_ff_output.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(primed_ff_correct)/len(primed_ff_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hcnn]",
   "language": "python",
   "name": "conda-env-.conda-hcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
