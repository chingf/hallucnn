{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085eb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from predify.utils.training import train_pcoders, eval_pcoders\n",
    "\n",
    "from models.networks_2022 import BranchedNetwork\n",
    "from data.NoisyDataset import NoisyDataset, FullNoisyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e30af",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2be7bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 'pnet'\n",
    "engram_dir = '/mnt/smb/locker/abbott-locker/hcnn/'\n",
    "activations_dir = f'{engram_dir}3_activations/{exp}/'\n",
    "pickles_dir = f'{engram_dir}pickles/{exp}_denoising/'\n",
    "os.makedirs(pickles_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104d0ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2cd337",
   "metadata": {},
   "source": [
    "# Distance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdc3533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few distance metrics\n",
    "\n",
    "def row_rms(A, B):\n",
    "    \"\"\"\n",
    "    RMS across rows\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    \n",
    "    if len(A.shape) == 1:\n",
    "        stim = A - B\n",
    "        return np.sqrt(np.mean(stim * stim, axis = 0))\n",
    "    \n",
    "    rmses = []\n",
    "    for idx in range(A.shape[0]):\n",
    "        a = A[idx]\n",
    "        b = B[idx]\n",
    "        a, b = a.T, b.T\n",
    "        stim = (a - b)\n",
    "        out = np.sqrt(np.mean(stim * stim, axis = 0))\n",
    "        rmses.append(out)\n",
    "    return np.mean(rmses)\n",
    "\n",
    "def rms(A, B):\n",
    "    \"\"\"\n",
    "    RMS of flattened vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "        \n",
    "    stim = A - B\n",
    "    out = np.sqrt(np.mean(stim * stim))\n",
    "\n",
    "    return out\n",
    "\n",
    "def tanimoto_distance(A, B):\n",
    "    \"\"\"\n",
    "    Tanimoto distance of flattened vector\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "    \n",
    "    _out = np.dot(A, B)/(np.linalg.norm(A)**2 + np.linalg.norm(B)**2 - np.dot(A,B))\n",
    "    return _out\n",
    "    \n",
    "def cosine_similarity(A, B):\n",
    "    \"\"\"\n",
    "    Cosine similarity of flattened vector\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "    \n",
    "    if len(A.shape) == 1:\n",
    "        return np.dot(A, B)/(np.linalg.norm(A)*np.linalg.norm(B))\n",
    "    \n",
    "    out = []\n",
    "    for channel in range(n_channels):\n",
    "        a = A[channel]\n",
    "        b = B[channel]\n",
    "        _out = np.dot(a, b)/(np.linalg.norm(a)+np.linalg.norm(b)-np.dot(a,b))\n",
    "        if np.isnan(_out):\n",
    "            print(f'nan: {np.linalg.norm(a)}, {np.linalg.norm(b)}')\n",
    "        out.append(_out)\n",
    "\n",
    "    return np.mean(out)\n",
    "\n",
    "def pearsonr_sim(A, B):\n",
    "    if torch.is_tensor(A):\n",
    "        A = A.numpy()\n",
    "    if torch.is_tensor(B):\n",
    "        B = B.numpy()\n",
    "    A = A.astype(float)\n",
    "    B = B.astype(float)\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "    pear, _ = pearsonr(A, B)\n",
    "    return pear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec993c",
   "metadata": {},
   "source": [
    "# Accuracy evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b144e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(results):\n",
    "    \"\"\" t is the timestep to eval \"\"\"\n",
    "    accuracies = [] # for timesteps {0,1,2,3,4}\n",
    "    n_timesteps = 4\n",
    "    labels = np.array(results['label'])\n",
    "    for t in range(n_timesteps+1):\n",
    "        acc_t = np.mean((results[f'{t}_output'] == labels))\n",
    "        accuracies.append(acc_t)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954794a4",
   "metadata": {},
   "source": [
    "# Function to collect correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "179c44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_correlations(results, dist_func, accs):\n",
    "    labels = np.array(results['label'])\n",
    "    idxs = np.arange(labels.size)\n",
    "    \n",
    "    popln_shuffle = []\n",
    "    popln_sim = []\n",
    "    popln_timestep = []\n",
    "    popln_layer = []\n",
    "    valid_score = []\n",
    "    \n",
    "    layers = ['conv1', 'conv2', 'conv3', 'conv4_W', 'conv5_W', 'fc6_W']\n",
    "    \n",
    "    n_timesteps = 4\n",
    "    for t in range(n_timesteps+1):\n",
    "        for l in layers:\n",
    "            for i in idxs:\n",
    "                noisy_activ = results[f'{l}_{t}_activations'][i]\n",
    "                shuff_idx = np.random.choice(idxs)\n",
    "                shuff_activ = results[f'{l}_{t}_clean_activations'][shuff_idx]\n",
    "                clean_activ = results[f'{l}_{t}_clean_activations'][i]\n",
    "                noisy_activ = noisy_activ.flatten()\n",
    "                shuff_activ = shuff_activ.flatten()\n",
    "                clean_activ = clean_activ.flatten()\n",
    "                dist = dist_func(noisy_activ, clean_activ)\n",
    "                shuff_dist = dist_func(noisy_activ, shuff_activ)\n",
    "                popln_shuffle.append(shuff_dist)\n",
    "                popln_sim.append(dist)\n",
    "                popln_timestep.append(t)\n",
    "                popln_layer.append(l)\n",
    "                valid_score.append(accs[t])\n",
    "        \n",
    "    results = {\n",
    "        'popln_shuffle': popln_shuffle,\n",
    "        'popln_sim': popln_sim,\n",
    "        'popln_timestep': popln_timestep,\n",
    "        'popln_layer': popln_layer,\n",
    "        'valid_score': valid_score\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e118447",
   "metadata": {},
   "source": [
    "# Run and save shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b57144d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is bad practice! But the warnings are real annoying\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd7cdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = 'pearsonr'\n",
    "dist_func = pearsonr_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddb89f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = ['pinkNoise', 'AudScene', 'Babble8Spkr']\n",
    "snrs = [-9., -6., -3., 0., 3.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units_per_layer = {\n",
    "    'conv1': (96, 55, 134), 'conv2': (256, 14, 34),\n",
    "    'conv3': (512, 7, 17), 'conv4_W': (1024, 7, 17),\n",
    "    'conv5_W': (512, 7, 17), 'fc6_W': (4096,)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bg in bgs:\n",
    "    for snr in snrs:\n",
    "        bg_snr_activations_dir = f'{activations_dir}{bg}_snr{int(snr)}/'\n",
    "        results = {\n",
    "            'popln_shuffle': [], 'popln_timestep': [],\n",
    "            'popln_sim': [], 'popln_layer': [], 'valid_score': []}\n",
    "        for hdf5_file in os.listdir(bg_snr_activations_dir):\n",
    "            hdf5_path = f'{bg_snr_activations_dir}{hdf5_file}'\n",
    "            hdf5_data = h5py.File(hdf5_path, 'r')\n",
    "            accs = eval_accuracy(hdf5_data)\n",
    "            _results = eval_correlations(hdf5_data, dist_func, accs)\n",
    "            for key in results.keys():\n",
    "                results[key].extend(_results[key])\n",
    "        with open(f'{pickles_dir}{file_prefix}_{bg}_snr{snr}.p', 'wb') as f:\n",
    "            pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18787069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
